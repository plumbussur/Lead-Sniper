import argparse
import sys
import os
import traceback
from typing import List

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def main():
    print("üîç –û—Ç–ª–∞–¥–∫–∞: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç–∏...")
    print(f"   –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
    print(f"   –§–∞–π–ª main.py: {os.path.abspath(__file__)}")
    print(f"   –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.path.dirname(os.path.dirname(os.path.abspath(__file__)))}")
    
    parser = argparse.ArgumentParser(description='–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö CAT-—Å–∏—Å—Ç–µ–º—ã')
    parser.add_argument('--output', '-o', default='data/companies.csv', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞')
    parser.add_argument('--collect', '-c', action='store_true', help='–°–æ–±—Ä–∞—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ')
    parser.add_argument('--analyze', '-a', action='store_true', help='–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ')
    parser.add_argument('--sources', nargs='+', default=['all'], 
                       choices=['rusprofile', 'catalog', 'all'], 
                       help='–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–±–æ—Ä–∞')
    
    args = parser.parse_args()
    
    print(f"üîç –û—Ç–ª–∞–¥–∫–∞: –ê—Ä–≥—É–º–µ–Ω—Ç—ã - {args}")
    
    try:
        if args.collect:
            collect_and_process_data(args.output, args.sources)
        elif args.analyze:
            analyze_existing_data(args.output)
        else:
            collect_and_process_data(args.output, args.sources)
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("üîç –ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:")
        traceback.print_exc()

def collect_and_process_data(output_path: str, sources: List[str]):
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö...")
    
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        print(f"üìÅ –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {output_dir}")
        os.makedirs(output_dir)
    
    try:
        from src.data_collectors.rusprofile_collector import RusprofileCollector
        from src.data_collectors.catalog_scanner import CatalogScanner
        from src.data_collectors.website_parser import WebsiteParser
        from src.processors.data_cleaner import DataCleaner
        from src.processors.revenue_validator import RevenueValidator
        from src.processors.cat_classifier import CatClassifier
        from src.utils.csv_handler import CsvHandler
        from config.settings import CONFIG
        
        all_companies = []
        
        if 'rusprofile' in sources or 'all' in sources:
            print("\nüìä –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å Rusprofile...")
            rusprofile_collector = RusprofileCollector()
            rusprofile_companies = rusprofile_collector.collect_companies()
            all_companies.extend(rusprofile_companies)
            print(f"   –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(rusprofile_companies)}")
        
        if 'catalog' in sources or 'all' in sources:
            print("\nüìö –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–æ–≤...")
            catalog_scanner = CatalogScanner()
            catalog_companies = catalog_scanner.collect_companies()
            all_companies.extend(catalog_companies)
            print(f"   –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(catalog_companies)}")
        
        print(f"üîç –û—Ç–ª–∞–¥–∫–∞: –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(all_companies)}")
        
        if not all_companies:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
            print("üìù –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª...")
            create_demo_file(output_path)
            return
        
        print("\nüßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        cleaned_companies = DataCleaner.clean_company_data(all_companies)
        print(f"   –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned_companies)}")
        
        print("\nüí∞ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤—ã—Ä—É—á–∫–µ...")
        revenue_filtered = RevenueValidator.filter_by_revenue(cleaned_companies)
        print(f"   –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≤—ã—Ä—É—á–∫–µ: {len(revenue_filtered)}")
        
        print("\nü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ CAT-—Å–∏—Å—Ç–µ–º–∞–º...")
        cat_classified = CatClassifier.classify_companies(revenue_filtered)
        print(f"   –ü–æ—Å–ª–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ CAT: {len(cat_classified)}")
        
        if not cat_classified:
            print("‚ö†Ô∏è  –ö–æ–º–ø–∞–Ω–∏–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç. –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            create_demo_file(output_path)
            return
        
        print("\nüåê –ê–Ω–∞–ª–∏–∑ —Å–∞–π—Ç–æ–≤ –∫–æ–º–ø–∞–Ω–∏–π...")
        website_parser = WebsiteParser()
        final_companies = website_parser.analyze_multiple_companies(cat_classified)
        
        print("\n‚ú® –£–ª—É—á—à–µ–Ω–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ CAT...")
        enhanced_companies = CatClassifier.enhance_cat_evidence(final_companies)
        
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ {output_path}...")
        print(f"üîç –û—Ç–ª–∞–¥–∫–∞: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: {os.path.abspath(output_path)}")
        
        CsvHandler.save_companies_to_csv(enhanced_companies, output_path)
        
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω! –†–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç")
        else:
            print(f"‚ùå –§–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω –ø–æ –ø—É—Ç–∏: {output_path}")
        
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìà –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {len(enhanced_companies)} –∫–æ–º–ø–∞–Ω–∏–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        print("üîç –ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:")
        traceback.print_exc()
        
        print("üìù –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª...")
        create_demo_file(output_path)

def create_demo_file(output_path: str):
    try:
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        demo_data = [
            {
                'inn': '7701234567',
                'name': '–û–û–û "–õ–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è –ü—Ä–æ"',
                'revenue': 150000000,
                'site': 'localization-pro.ru',
                'cat_evidence': '—É–ø–æ–º–∏–Ω–∞–Ω–∏–µ Trados Studio',
                'source': 'demo',
                'cat_product': 'Trados Studio',
                'employees': '25',
                'okved_main': '62.01',
                'country': '–†–æ—Å—Å–∏—è'
            },
            {
                'inn': '7712345678',
                'name': '–ê–û "–¢—Ä–∞–Ω—Å–ª–µ–π—Ç –¢–µ—Ö"',
                'revenue': 200000000,
                'site': 'translatetech.ru',
                'cat_evidence': '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ TMS',
                'source': 'demo',
                'cat_product': '–°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è TMS',
                'employees': '45',
                'okved_main': '62.02',
                'country': '–†–æ—Å—Å–∏—è'
            },
            {
                'inn': '7812345678',
                'name': '–û–û–û "–ì–ª–æ–±–∞–ª –¢—Ä–∞–Ω—Å–ª–µ–π—Ç"',
                'revenue': 300000000,
                'site': 'global-translate.com',
                'cat_evidence': '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ MemoQ; —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤',
                'source': 'demo',
                'cat_product': 'MemoQ',
                'employees': '80',
                'okved_main': '74.30',
                'country': '–†–æ—Å—Å–∏—è'
            }
        ]
        
        import pandas as pd
        df = pd.DataFrame(demo_data)
        df.to_csv(output_path, index=False, encoding='utf-8')
        
        print(f"‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {output_path}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")

def analyze_existing_data(csv_path: str):
    print(f"üìä –ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ {csv_path}...")
    
    try:
        from src.utils.csv_handler import CsvHandler
        
        companies = CsvHandler.load_companies_from_csv(csv_path)
        if not companies:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return
        
        print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(companies)}")
        
        revenues = [c.revenue for c in companies if c.revenue]
        if revenues:
            print(f"üí∞ –°—Ä–µ–¥–Ω—è—è –≤—ã—Ä—É—á–∫–∞: {sum(revenues) / len(revenues):,.0f} ‚ÇΩ")
            print(f"üí∞ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Ä—É—á–∫–∞: {max(revenues):,.0f} ‚ÇΩ")
            print(f"üí∞ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Ä—É—á–∫–∞: {min(revenues):,.0f} ‚ÇΩ")
        
        sources = {}
        for company in companies:
            source = company.source
            sources[source] = sources.get(source, 0) + 1
        
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
        for source, count in sources.items():
            print(f"   {source}: {count}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")

if __name__ == "__main__":
    main()